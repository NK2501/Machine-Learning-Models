{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51776d5d",
   "metadata": {},
   "source": [
    "# Regularized regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "46ee0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "989bffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston=pd.read_csv(\"Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cf854b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.45948838509025\n",
      "[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n"
     ]
    }
   ],
   "source": [
    "x=boston.drop('medv',axis=1)\n",
    "y=boston['medv']\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(x,y)\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50fb92fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.782429511205018\n",
      "25.358577194006944\n",
      "0.6947991644651352\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=23)\n",
    "lr1=LinearRegression()\n",
    "lr1.fit(x_train,y_train)\n",
    "y_pred=lr1.predict(x_test)\n",
    "print(mae(y_test,y_pred))\n",
    "print(mse(y_test,y_pred))\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b28ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv(\"Diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4f69f1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191455174725736\n"
     ]
    }
   ],
   "source": [
    "dum_dia=pd.get_dummies(diamonds,drop_first=True)\n",
    "dia_train,dia_test=train_test_split(dum_dia,test_size=0.3,random_state=23)\n",
    "x_train=dia_train.drop('price',axis=1)\n",
    "y_train=dia_train['price']\n",
    "x_test=dia_test.drop('price',axis=1)\n",
    "y_test=dia_test['price']\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0860ebe",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "46493b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv(\"Diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8baed466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha= 0.01 R2= 0.9191313060296065\n",
      "Alpha= 0.15 R2= 0.9191313060296065\n",
      "Alpha= 0.5 R2= 0.9191313060296065\n",
      "Alpha= 0.75 R2= 0.9191313060296065\n",
      "Alpha= 1 R2= 0.9191313060296065\n",
      "Alpha= 2 R2= 0.9191313060296065\n",
      "Alpha= 2.4 R2= 0.9191313060296065\n",
      "Alpha= 4 R2= 0.9191313060296065\n"
     ]
    }
   ],
   "source": [
    "dum_dia=pd.get_dummies(diamonds,drop_first=True)\n",
    "dia_train,dia_test=train_test_split(dum_dia,test_size=0.3,random_state=23)\n",
    "x_train=dia_train.drop('price',axis=1)\n",
    "y_train=dia_train['price']\n",
    "x_test=dia_test.drop('price',axis=1)\n",
    "y_test=dia_test['price']\n",
    "\n",
    "alphas=[0.01,0.15,0.5,0.75,1,2,2.4,4]\n",
    "for v in alphas:\n",
    "    ridge=Ridge()\n",
    "    ridge.fit(x_train,y_train)\n",
    "    #print(ridge.coef_)\n",
    "    y_pred=ridge.predict(x_test)\n",
    "    scr=r2_score(y_test,y_pred)\n",
    "    print(\"Alpha=\",v,\"R2=\",scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "28ea0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "salari = pd.read_csv(\"Salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "12c7174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3639884340881161\n"
     ]
    }
   ],
   "source": [
    "dum_sal=pd.get_dummies(salari,drop_first=True)\n",
    "sal_train,sal_test=train_test_split(dum_sal,test_size=0.3,random_state=23)\n",
    "x_train=sal_train.drop('salary',axis=1)\n",
    "y_train=sal_train['salary']\n",
    "x_test=sal_test.drop('salary',axis=1)\n",
    "y_test=sal_test['salary']\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95be8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston=pd.read_csv(\"Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "79ad7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha= 0.01 R2= 0.6913170388069763\n",
      "Alpha= 0.15 R2= 0.6913170388069763\n",
      "Alpha= 0.5 R2= 0.6913170388069763\n",
      "Alpha= 0.75 R2= 0.6913170388069763\n",
      "Alpha= 1 R2= 0.6913170388069763\n",
      "Alpha= 2 R2= 0.6913170388069763\n",
      "Alpha= 2.4 R2= 0.6913170388069763\n",
      "Alpha= 4 R2= 0.6913170388069763\n"
     ]
    }
   ],
   "source": [
    "dum_bs=pd.get_dummies(boston,drop_first=True)\n",
    "bs_train,bs_test=train_test_split(dum_bs,test_size=0.3,random_state=23)\n",
    "x_train=bs_train.drop('medv',axis=1)\n",
    "y_train=bs_train['medv']\n",
    "x_test=bs_test.drop('medv',axis=1)\n",
    "y_test=bs_test['medv']\n",
    "\n",
    "alphas=[0.01,0.15,0.5,0.75,1,2,2.4,4]\n",
    "for v in alphas:\n",
    "    ridge=Ridge()\n",
    "    ridge.fit(x_train,y_train)\n",
    "    #print(ridge.coef_)\n",
    "    y_pred=ridge.predict(x_test)\n",
    "    scr=r2_score(y_test,y_pred)\n",
    "    print(\"Alpha=\",v,\"R2=\",scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f051938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "salari = pd.read_csv(\"Salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ae55c8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha= 9.474052631578948\n",
      "Best score= 0.37072913330268276\n"
     ]
    }
   ],
   "source": [
    "dum_sal=pd.get_dummies(salari,drop_first=True)\n",
    "sal_train,sal_test=train_test_split(dum_sal,test_size=0.3,random_state=23)\n",
    "x_train=sal_train.drop('salary',axis=1)\n",
    "y_train=sal_train['salary']\n",
    "x_test=sal_test.drop('salary',axis=1)\n",
    "y_test=sal_test['salary']\n",
    "alphas=np.linspace(0.001,15,20)#[0.01,0.15,0.5,0.75,1,2,2.4,4]\n",
    "scores=[]\n",
    "for v in alphas:\n",
    "    ridge=Ridge(alpha=v)\n",
    "    ridge.fit(x_train,y_train)\n",
    "    #print(ridge.coef_)\n",
    "    y_pred=ridge.predict(x_test)\n",
    "    scr=r2_score(y_test,y_pred)\n",
    "    scores.append(scr)\n",
    "    #print(\"Alpha=\",v,\"R2=\",scr)\n",
    "i_max=np.argmax(scores)\n",
    "print(\"Best alpha=\",alphas[i_max])\n",
    "print(\"Best score=\",scores[i_max])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b4f786b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas,scores)\n",
    "plt.scatter(alphas,scores,c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bf88d",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1cd9760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha= 0.001\n",
      "Best score= 0.3691577381153066\n"
     ]
    }
   ],
   "source": [
    "dum_sal=pd.get_dummies(salari,drop_first=True)\n",
    "sal_train,sal_test=train_test_split(dum_sal,test_size=0.3,random_state=23)\n",
    "x_train=sal_train.drop('salary',axis=1)\n",
    "y_train=sal_train['salary']\n",
    "x_test=sal_test.drop('salary',axis=1)\n",
    "y_test=sal_test['salary']\n",
    "alphas=np.linspace(0.001,15,20)#[0.01,0.15,0.5,0.75,1,2,2.4,4]\n",
    "scores=[]\n",
    "for v in alphas:\n",
    "    lasso=Lasso(alpha=v)\n",
    "    lasso.fit(x_train,y_train)\n",
    "    #print(ridge.coef_)\n",
    "    y_pred=ridge.predict(x_test)\n",
    "    scr=r2_score(y_test,y_pred)\n",
    "    scores.append(scr)\n",
    "    #print(\"Alpha=\",v,\"R2=\",scr)\n",
    "i_max=np.argmax(scores)\n",
    "print(\"Best alpha=\",alphas[i_max])\n",
    "print(\"Best score=\",scores[i_max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1869d",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9994a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha= {'alpha': 0.1, 'L1_ratio': 0.75}\n",
      "Best score= 0.37044748848850784\n"
     ]
    }
   ],
   "source": [
    "dum_sal=pd.get_dummies(salari,drop_first=True)\n",
    "sal_train,sal_test=train_test_split(dum_sal,test_size=0.3,random_state=23)\n",
    "x_train=sal_train.drop('salary',axis=1)\n",
    "y_train=sal_train['salary']\n",
    "x_test=sal_test.drop('salary',axis=1)\n",
    "y_test=sal_test['salary']\n",
    "alphas=[0.001,0.1,0.5,1,2]\n",
    "l1_s=[0.001,0.25,0.75]\n",
    "scores=[]\n",
    "params=[]\n",
    "for v in alphas:\n",
    "    for l1 in l1_s:\n",
    "        elast=ElasticNet(alpha=v,l1_ratio=l1)\n",
    "        elast.fit(x_train,y_train)\n",
    "        #print(ridge.coef_)\n",
    "        y_pred=elast.predict(x_test)\n",
    "        scr=r2_score(y_test,y_pred)\n",
    "        params.append({'alpha':v,'L1_ratio':l1})\n",
    "        scores.append(scr)\n",
    "        #print(\"Alpha=\",v,\"R2=\",scr)\n",
    "    \n",
    "i_max=np.argmax(scores)\n",
    "print(\"Best alpha=\",params[i_max])\n",
    "print(\"Best score=\",scores[i_max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f23c2",
   "metadata": {},
   "source": [
    "# k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "05f50256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.600e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.413e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.289e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.440e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.756e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.006e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.697e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.569e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.146e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.454e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.107e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.105e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.965e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.425e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.767e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.399e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.415e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.253e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.649e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.018e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.634e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.659e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.488e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.840e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.231e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.834e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.864e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.689e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.418e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.008e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.042e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.867e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.159e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.585e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.165e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.200e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.028e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.297e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.737e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.307e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.343e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.175e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.423e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.437e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.473e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.310e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.541e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.007e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.558e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.593e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.436e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.650e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.128e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.671e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.704e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.554e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.753e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.241e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.776e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.808e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.664e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.850e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.348e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.875e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.905e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.769e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.449e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.968e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.997e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.868e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.027e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.544e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.057e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.083e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.961e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.110e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.635e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.141e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.165e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.050e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.188e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.722e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.221e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.243e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.135e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.263e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.804e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.297e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.317e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.216e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.334e+03, tolerance: 3.393e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.883e+03, tolerance: 3.591e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.370e+03, tolerance: 3.350e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.387e+03, tolerance: 3.407e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.294e+03, tolerance: 3.340e+00 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha = {'alpha': 0.001, 'l1_ratio': 0.7777777777777777} \n",
      "Best score = 0.7186437570680854\n"
     ]
    }
   ],
   "source": [
    "boston = pd.read_csv(\"Boston.csv\")\n",
    "x = boston.drop('medv',axis=1)\n",
    "y=boston[\"medv\"]\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True,random_state=23)\n",
    "\n",
    "alphas = np.linspace(0.001,15,20)\n",
    "l1_s = np.linspace(0,1,10)\n",
    "\n",
    "score = []\n",
    "param = []\n",
    "\n",
    "for v in alphas:\n",
    "    for l1 in l1_s:\n",
    "        elast = ElasticNet(alpha=v, l1_ratio=l1)\n",
    "        result = cross_val_score(elast,x,y,cv=kfold)\n",
    "        scr = np.mean(result)\n",
    "        score.append(scr)\n",
    "        param.append({'alpha' :v, 'l1_ratio' : l1})\n",
    "    \n",
    "i_max = np.argmax(score)#return index of max value\n",
    "print(f\"Best alpha = {param[i_max]} \\nBest score = {score[i_max]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0124d854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
